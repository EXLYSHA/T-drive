{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  10%|▉         | 1034/10356 [00:24<03:38, 42.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1766</td>\n",
       "      <td>2008-02-02 13:47:24</td>\n",
       "      <td>116.42342</td>\n",
       "      <td>39.83735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1766</td>\n",
       "      <td>2008-02-02 13:57:25</td>\n",
       "      <td>116.42343</td>\n",
       "      <td>39.83725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1766</td>\n",
       "      <td>2008-02-02 14:07:24</td>\n",
       "      <td>116.42339</td>\n",
       "      <td>39.83720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1766</td>\n",
       "      <td>2008-02-02 14:17:24</td>\n",
       "      <td>116.42334</td>\n",
       "      <td>39.83726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1766</td>\n",
       "      <td>2008-02-02 14:27:24</td>\n",
       "      <td>116.42342</td>\n",
       "      <td>39.83728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>2061</td>\n",
       "      <td>2008-02-08 17:23:38</td>\n",
       "      <td>40.31350</td>\n",
       "      <td>116.68677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>2061</td>\n",
       "      <td>2008-02-08 17:28:37</td>\n",
       "      <td>40.31353</td>\n",
       "      <td>116.68677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>2061</td>\n",
       "      <td>2008-02-08 17:33:37</td>\n",
       "      <td>40.31353</td>\n",
       "      <td>116.68677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>2061</td>\n",
       "      <td>2008-02-08 17:38:37</td>\n",
       "      <td>39.96895</td>\n",
       "      <td>116.68678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>2061</td>\n",
       "      <td>2008-02-08 17:38:37</td>\n",
       "      <td>39.96895</td>\n",
       "      <td>116.68678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1831757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      taxi_id                 time   latitude  longitude\n",
       "0        1766  2008-02-02 13:47:24  116.42342   39.83735\n",
       "1        1766  2008-02-02 13:57:25  116.42343   39.83725\n",
       "2        1766  2008-02-02 14:07:24  116.42339   39.83720\n",
       "3        1766  2008-02-02 14:17:24  116.42334   39.83726\n",
       "4        1766  2008-02-02 14:27:24  116.42342   39.83728\n",
       "...       ...                  ...        ...        ...\n",
       "1656     2061  2008-02-08 17:23:38   40.31350  116.68677\n",
       "1657     2061  2008-02-08 17:28:37   40.31353  116.68677\n",
       "1658     2061  2008-02-08 17:33:37   40.31353  116.68677\n",
       "1659     2061  2008-02-08 17:38:37   39.96895  116.68678\n",
       "1660     2061  2008-02-08 17:38:37   39.96895  116.68678\n",
       "\n",
       "[1831757 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "path = \"./data/taxi_log_2008_by_id\"\n",
    "os.chdir(path)\n",
    "files = os.listdir()\n",
    "\n",
    "total_files = len(files[1:])\n",
    "target_files = int(total_files * 0.1)\n",
    "\n",
    "gps_data=pd.read_csv(files[0],names=['taxi_id','time','latitude','longitude'])\n",
    "\n",
    "for i,file in enumerate(tqdm(files[1:], desc=\"Processing files\")):\n",
    "    tmp = pd.read_csv(file, names=['taxi_id', 'time', 'longitude', 'latitude'])\n",
    "    if not tmp.empty:\n",
    "        gps_data = pd.concat([gps_data, tmp])\n",
    "    if i + 1 >= target_files:\n",
    "        break\n",
    " \n",
    "gps_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:39:08</td>\n",
       "      <td>39.88957</td>\n",
       "      <td>116.35743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:44:08</td>\n",
       "      <td>39.89726</td>\n",
       "      <td>116.35732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:49:09</td>\n",
       "      <td>39.90712</td>\n",
       "      <td>116.35060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:54:09</td>\n",
       "      <td>39.91145</td>\n",
       "      <td>116.35171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:59:08</td>\n",
       "      <td>39.89655</td>\n",
       "      <td>116.34366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697459</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:10:49</td>\n",
       "      <td>40.21196</td>\n",
       "      <td>116.24457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697460</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:15:51</td>\n",
       "      <td>40.21237</td>\n",
       "      <td>116.25047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697461</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:20:53</td>\n",
       "      <td>40.22385</td>\n",
       "      <td>116.23035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697462</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:24:45</td>\n",
       "      <td>40.22432</td>\n",
       "      <td>116.23075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697463</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:29:52</td>\n",
       "      <td>40.22419</td>\n",
       "      <td>116.23070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1697464 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         taxi_id                time  latitude  longitude\n",
       "0              3 2008-02-02 13:39:08  39.88957  116.35743\n",
       "1              3 2008-02-02 13:44:08  39.89726  116.35732\n",
       "2              3 2008-02-02 13:49:09  39.90712  116.35060\n",
       "3              3 2008-02-02 13:54:09  39.91145  116.35171\n",
       "4              3 2008-02-02 13:59:08  39.89655  116.34366\n",
       "...          ...                 ...       ...        ...\n",
       "1697459    10356 2008-02-07 22:10:49  40.21196  116.24457\n",
       "1697460    10356 2008-02-07 22:15:51  40.21237  116.25047\n",
       "1697461    10356 2008-02-07 22:20:53  40.22385  116.23035\n",
       "1697462    10356 2008-02-07 22:24:45  40.22432  116.23075\n",
       "1697463    10356 2008-02-07 22:29:52  40.22419  116.23070\n",
       "\n",
       "[1697464 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps_data1=gps_data.sort_values(by=['taxi_id','time'],ignore_index=True)\n",
    "gps_data1.drop_duplicates(inplace=True,ignore_index=True)\n",
    "gps_data1['time'] = pd.to_datetime(gps_data1['time'])\n",
    "gps_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:39:08</td>\n",
       "      <td>39.88957</td>\n",
       "      <td>116.35743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:44:08</td>\n",
       "      <td>39.89726</td>\n",
       "      <td>116.35732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:49:09</td>\n",
       "      <td>39.90712</td>\n",
       "      <td>116.35060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:54:09</td>\n",
       "      <td>39.91145</td>\n",
       "      <td>116.35171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-02-02 13:59:08</td>\n",
       "      <td>39.89655</td>\n",
       "      <td>116.34366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697459</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:10:49</td>\n",
       "      <td>40.21196</td>\n",
       "      <td>116.24457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697460</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:15:51</td>\n",
       "      <td>40.21237</td>\n",
       "      <td>116.25047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697461</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:20:53</td>\n",
       "      <td>40.22385</td>\n",
       "      <td>116.23035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697462</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:24:45</td>\n",
       "      <td>40.22432</td>\n",
       "      <td>116.23075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697463</th>\n",
       "      <td>10356</td>\n",
       "      <td>2008-02-07 22:29:52</td>\n",
       "      <td>40.22419</td>\n",
       "      <td>116.23070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1688288 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         taxi_id                time  latitude  longitude\n",
       "0              3 2008-02-02 13:39:08  39.88957  116.35743\n",
       "1              3 2008-02-02 13:44:08  39.89726  116.35732\n",
       "2              3 2008-02-02 13:49:09  39.90712  116.35060\n",
       "3              3 2008-02-02 13:54:09  39.91145  116.35171\n",
       "4              3 2008-02-02 13:59:08  39.89655  116.34366\n",
       "...          ...                 ...       ...        ...\n",
       "1697459    10356 2008-02-07 22:10:49  40.21196  116.24457\n",
       "1697460    10356 2008-02-07 22:15:51  40.21237  116.25047\n",
       "1697461    10356 2008-02-07 22:20:53  40.22385  116.23035\n",
       "1697462    10356 2008-02-07 22:24:45  40.22432  116.23075\n",
       "1697463    10356 2008-02-07 22:29:52  40.22419  116.23070\n",
       "\n",
       "[1688288 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps_data1=gps_data1[(gps_data1['latitude']>39.4)&\n",
    "                  (gps_data1['latitude']<41.6)&\n",
    "                  (gps_data1['longitude']>115.7)&\n",
    "                  (gps_data1['longitude']<117.4)]\n",
    "gps_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "\n",
    "total_samples = 0\n",
    "for _, group in gps_data1.groupby('taxi_id'):\n",
    "    n_samples = len(group) - window_size\n",
    "    if n_samples > 0:\n",
    "        total_samples += n_samples\n",
    "\n",
    "X = np.zeros((total_samples, window_size, 3))\n",
    "y = np.zeros((total_samples, 2))\n",
    "\n",
    "sample_idx = 0\n",
    "\n",
    "for taxi_id, group in gps_data1.groupby('taxi_id'):\n",
    "    n_samples = len(group) - window_size\n",
    "    if n_samples <= 0:\n",
    "        continue\n",
    "    \n",
    "    loc_data = group[['latitude', 'longitude']].values\n",
    "    time_data = group['time'].values\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        loc_features = loc_data[i:i+window_size]\n",
    "        \n",
    "        time_diff = (time_data[i:i+window_size] - time_data[i]).astype('timedelta64[ms]').astype(float) / 1000\n",
    "        time_diff = time_diff.reshape(-1, 1)\n",
    "        \n",
    "        seq_input = np.hstack([loc_features, time_diff])\n",
    "        \n",
    "        target = loc_data[i+window_size]\n",
    "        \n",
    "        if sample_idx < total_samples:\n",
    "            X[sample_idx] = seq_input\n",
    "            y[sample_idx] = target\n",
    "            sample_idx += 1\n",
    "        else:\n",
    "            print(f\"warning: sample_idx={sample_idx} beyond {total_samples}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "train_X, train_y = X[:int(n*0.8)], y[:int(n*0.8)]\n",
    "val_X, val_y = X[int(n*0.8):int(n*0.9)], y[int(n*0.8):int(n*0.9)]\n",
    "test_X, test_y = X[int(n*0.9):], y[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TaxiDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TaxiDataset(train_X, train_y)\n",
    "val_dataset = TaxiDataset(val_X, val_y)\n",
    "test_dataset = TaxiDataset(test_X, test_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxiTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TaxiTransformer, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)  # 将输入映射到 d_model 维度\n",
    "        \n",
    "        # 位置编码\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, 3, d_model))  # 位置编码参数\n",
    "\n",
    "        # 设置 batch_first=True 以优化计算\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                                   dim_feedforward=dim_feedforward, dropout=dropout, \n",
    "                                                   batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.output_layer = nn.Linear(d_model, 2)  # 输出经纬度\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, window_size, input_dim]\n",
    "        x = self.input_linear(x)  # [batch_size, window_size, d_model]\n",
    "        # 添加位置编码\n",
    "        x = self.norm(x)\n",
    "        x = x + self.positional_encoding\n",
    "        # 直接传入 Transformer（不需要 .transpose(0,1)）\n",
    "        x = self.transformer_encoder(x)\n",
    "        # 提取最后一个时间步的输出\n",
    "        x_last = x[:, -1, :]  # [batch_size, d_model]\n",
    "        output = self.output_layer(x_last)  # [batch_size, 2]\n",
    "        return output\n",
    "\n",
    "# Model hyperparameters\n",
    "input_dim = 3\n",
    "d_model = 64\n",
    "nhead = 8\n",
    "num_layers = 2\n",
    "dim_feedforward = 128\n",
    "model = TaxiTransformer(input_dim, d_model, nhead, num_layers, dim_feedforward)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(preds, batch_y)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m, in \u001b[0;36mTaxiTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 直接传入 Transformer（不需要 .transpose(0,1)）\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 提取最后一个时间步的输出\u001b[39;00m\n\u001b[1;32m     27\u001b[0m x_last \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# [batch_size, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:517\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    514\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 517\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    525\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:920\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    916\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m    919\u001b[0m         x\n\u001b[0;32m--> 920\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m     )\n\u001b[1;32m    922\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:943\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    932\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    933\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    934\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    935\u001b[0m         x,\n\u001b[1;32m    936\u001b[0m         x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    942\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout1\u001b[49m(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1922\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1921\u001b[0m     _buffers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 1922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _buffers:\n\u001b[1;32m   1923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _buffers[name]\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_modules\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(batch_X)\n",
    "        loss = criterion(preds, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch_X.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            preds = model(batch_X)\n",
    "            loss = criterion(preds, batch_y)\n",
    "            val_loss += loss.item() * batch_X.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0218\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        preds = model(batch_X)\n",
    "        loss = criterion(preds, batch_y)\n",
    "        test_loss += loss.item() * batch_X.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
